{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week11_Discussion.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPjk+QxYW4bqERnHh9Bb+Lp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MrinmayeeKulkarni/Cloud-Computing-Weekly-Discussion/blob/master/Week11_Discussion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuFYfeJeeOqP",
        "colab_type": "text"
      },
      "source": [
        "### What problems does Hadoop Solve?\n",
        "Flexibility due to variety- Hadoop accepts data from variety of sources and formats (structured and unstructured). This means organizations can use Hadoop to derive valuable insights from data sources such as social media, email conversations.  Hadoop can be used for a wide variety of purposes, such as log processing, recommendation systems, data warehousing, market campaign analysis and fraud detection.\n",
        "\n",
        "* Clustering system- It is cost effective as it uses cluster of commodity hardware and so can be cheap to store data.\n",
        "\n",
        "* Performance- It is distributed processing and storage architecture and processes vast amounts of data very fast. It divides data into batches and distributes it to the nodes in the cluster with the task code through MapReduce to execute codes in parallel. \n",
        "\n",
        "* Resilient to failures- The key advantage is fault tolerance due to redundancy. As data is sent to a node, it is replicated and therefore in case of a failure can be retrieved.\n",
        "\n",
        "* Open source- The code is easily available due to open source technology and can be used to customize requirements.\n",
        "\n",
        "* Scalable- It is highly scalable as; it can store and distribute very large data sets across hundreds of inexpensive servers that operate in parallel.\n",
        "\n",
        "* Multiple language supported platform \n",
        "\n",
        "### What are the key differences between Hadoop and Spark?\n",
        "Hadoop is a disk-based batch processing system which reads data from disk and saves the results back to the disk. But many times, extremely fast streaming applications require real-time data would not work well with disk-based system.\n",
        "\n",
        "* Spark is easier to program and doesnâ€™t require abstraction.\n",
        "\n",
        "* Due to replication as fault tolerance Hadoop has more disk-based overhead. Resilient distributed databases RDDs like Spark eliminate this overhead by being in-memory (using disk only when data would not fit in memory). Spark has this interesting way of fault tolerance by remembering the steps used to create the RDDs so it can be rebuilt in case of failure.\n",
        "\n",
        "* Programmers can perform streaming, batch processing and machine learning ,all in the same cluster.\n",
        "\n",
        "* Executes jobs 10-100 time faster than Hadoop MapReduce.\n",
        "\n",
        "### Post a screenshot of a lab where you had difficulty with a concept or learned something.\n"
      ]
    }
  ]
}